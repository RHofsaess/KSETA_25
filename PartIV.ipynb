{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "5c7f694d",
   "metadata": {},
   "source": [
    "# Part IV: (Why) Is Python slow?\n",
    "While Python is a very convenient and user-friendly language, it is considered as one of the slower ones.\n",
    "Is this really the case? If yes, why? And how we can mitigate that? We will have a look!\n",
    "\n",
    "In general applies, Python has an overhead of several function calls an invocations per executed command.\n",
    "Naturally, this makes often reoccuring things less performant, as it is not compiler-optimizable.\n",
    "\n",
    "The best example are **loops**.\n",
    "\n",
    "Since Python is based on C, this is the most natural comparison:"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "90b90d26-23c9-490f-bfa3-72b13f733d73",
   "metadata": {},
   "source": [
    "## Loops\n",
    "Loops are a good example for syntactics that should be avoided in performant code,"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7de541d8-e058-453a-9fbb-7bf4cb495334",
   "metadata": {},
   "source": [
    "### Python"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "6c25b2a9-91f2-4e8a-a2d7-e63d5d6caf58",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sum: 49999995000000\n",
      "CPU times: user 857 ms, sys: 160 ms, total: 1.02 s\n",
      "Wall time: 1.01 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "N = 10000000\n",
    "data = list(range(N))\n",
    "\n",
    "total = 0\n",
    "for x in data:\n",
    "    total += x\n",
    "print(\"Sum:\", total)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f734cc9b-1148-4b0f-90e2-f7b7171a9e81",
   "metadata": {},
   "source": [
    "### C"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "061024de-471f-4ce1-a102-eaf53af8ded5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# !cat speed_comparison/sum_loop.c  # Comment in to show C code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "6e7c5b4d",
   "metadata": {},
   "outputs": [],
   "source": [
    "!gcc -O3 speed_comparison/sum_loop.c -o sum_loop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "ba754b2c-0a81-4638-9c63-42f8968b9167",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 2 µs, sys: 1e+03 ns, total: 3 µs\n",
      "Wall time: 12.4 µs\n",
      "Sum: 49999995000000"
     ]
    }
   ],
   "source": [
    "%time\n",
    "!./sum_loop"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "91d4fb33-525e-4135-a38b-19673d57455d",
   "metadata": {},
   "source": [
    "**Question**: Why is C so much faster?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "19c11196-6220-420a-8d5f-eadb0ef1767a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "C implements low-level arithmetics and high-performant, pre-compiled, and optimized loops. On top, Python has the comparably large interpreter overhead.\n"
     ]
    }
   ],
   "source": [
    "from solutions import solution_speed2\n",
    "print(solution_speed2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dcf90ac2-cb16-4fc0-b7df-b09db797f80a",
   "metadata": {},
   "source": [
    "## Interpreter Overhead\n",
    "Python introduces an interpreter overhead, compared to compiled languages, like C.\n",
    "A simple addition, for example, is not only an arithmetic add, but involves several additional steps:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "28c8eee9-7145-4942-a458-f7557d8e88f2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  4           0 RESUME                   0\n",
      "\n",
      "  5           2 LOAD_FAST                0 (a)\n",
      "              4 LOAD_FAST                1 (b)\n",
      "              6 BINARY_OP                0 (+)\n",
      "             10 RETURN_VALUE\n"
     ]
    }
   ],
   "source": [
    "# The high-level byte-code is rather similar to C\n",
    "import dis\n",
    "\n",
    "def f(a, b):\n",
    "    return a + b\n",
    "\n",
    "dis.dis(f)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2803276a-f53d-48d1-8910-7a000f6abc5a",
   "metadata": {},
   "source": [
    "While for C, this directly translates in assembler operations, the individual executions are interpreted in Python, which is essentially happening in a large while loop with different cases:\n",
    "```\n",
    "for (;;) {\n",
    "    switch (opcode) {\n",
    "        case LOAD_FAST:\n",
    "            ...\n",
    "        case BINARY_ADD:\n",
    "            v = PyNumber_Add(v, w);\n",
    "            ...\n",
    "        ...\n",
    "    }\n",
    "}\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6c31fb8d-e557-4201-a789-c43a8d34a069",
   "metadata": {},
   "source": [
    "A simple addition is implemented in C in three reister instructions: \n",
    "```\n",
    "mov eax, edi\n",
    "add eax, esi\n",
    "ret\n",
    "```\n",
    "In Python however, several langauge-intrinsic things cause a large overhead (PER OPERATION!):\n",
    "```\n",
    "1) Parse a + b -> AST; convert to bytecode (LOAD_FAST a, LOAD_FAST b, BINARY_OP +).\n",
    "2) Interpreter runs BINARY_OP; may specialize to ADD_INT/ADD_FLOAT based on observed types.\n",
    "3) Dispatch: call PyNumber_Add(a, b), an abstracted c_call from the CPython implementation..\n",
    "4) Slots: try a.__add__(b); if NotImplemented, try b.__radd__(a); else TypeError.\n",
    "5) Types match! -> int + int: arbitrary-precision in PyLongObject; fast word add then fallback to multi-precision on overflow; allocate new PyLong; normalize; update refcounts.\n",
    "6) In case of float: float + float: add C doubles (IEEE-754); allocate new PyFloatObject; handle inf/NaN per platform.\n",
    "7) Mixed types: numeric coercion rules (e.g., int + float -> float).\n",
    "8) In-place +=: uses __iadd__ if defined, else normal add; immutables (int, float) always allocate new. Under the hood: call CPzthon PyNumber_InPlaceAdd;\n",
    "9) Memory/GIL: objects allocated via CPython allocators; refcounted; GIL ensures interpreter safety -> prevents that during all those steps, another thread/operation alters the currently used objects.\n",
    "```\n",
    "\n",
    "Especially 9) is one of the main arguments for the GIL!"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6b1d5200-780c-4046-bf7f-cb960a578236",
   "metadata": {},
   "source": [
    "**Take-away**: Instead of three low-level arithmetics instructions, a simple addition in Python calls a whole stack of function calls, allocations, validations, etc. All this happens automatically in the background and makes the language very convenient to use, BUT at the cost of reduced performance!"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7c8d72c5-1cae-484f-a5fb-59cfa504ba6a",
   "metadata": {},
   "source": [
    "## Let's make it even worse: Print()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "52715ddc-a502-4eba-b260-397d33486270",
   "metadata": {},
   "source": [
    "### Python"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "dc5e1075-b758-4b5f-a3b2-784486cdf577",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 163 ms, sys: 133 ms, total: 296 ms\n",
      "Wall time: 14.2 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "!python3 speed_comparison/sum_loop_print.py > output_py.txt"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "beeee0bc-ab12-4339-9019-d7b4225f7051",
   "metadata": {},
   "source": [
    "### C"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "87dbc383-f019-4d11-943c-a0e077132c15",
   "metadata": {},
   "outputs": [],
   "source": [
    "!gcc -O3 speed_comparison/sum_loop_print.c -o sum_loop_print"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "5d799eee-3f52-458d-b934-b7d7af813a54",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 70.9 ms, sys: 99.5 ms, total: 170 ms\n",
      "Wall time: 8.69 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "!./sum_loop_print > output_C.txt"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dad601bc-dcf2-47ac-95c0-22c73d176b4c",
   "metadata": {},
   "source": [
    "Note that C also suffers a lot from the prints! In general applies: **Only print what you really need and remove/hide e.g. debug outputs etc in production software.**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5ff26940-249b-407c-b7a7-4e2a8e69f325",
   "metadata": {},
   "source": [
    "## How about if?\n",
    "In C(++), avoiding branching within loops to reduce bad prediction occurences is a common optimization strategy.\n",
    "This is the only \"good news\" in Python: we do not need to care (mostly).\n",
    "\n",
    "Due to the GIL and the generally slower execution, branch predictions are not really making a difference, if we do not use lowest level things."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5c8f733e-8137-4e8e-b2c0-41257679ca2a",
   "metadata": {},
   "source": [
    "## Optimization Strategies and Good Practices\n",
    "As we have seen, default Python is very slow, especially with loops.\n",
    "But often, this can be covered and mitigated with good coding practices.\n",
    "\n",
    "In the following, we will have a look at different opimization strategies."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ac50e3fe-3c60-4eba-97de-c80e6a461815",
   "metadata": {},
   "source": [
    "### Starting Point: A simple nested for loop with an inplace addition of a division"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "bf5b9f9e-fc84-43e0-a997-4872c5860e28",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "489223499.9991652\n",
      "CPU times: user 14.7 s, sys: 0 ns, total: 14.7 s\n",
      "Wall time: 14.7 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "total = 0.0\n",
    "for i in range(9999):\n",
    "    for j in range(1, 9999):\n",
    "        total += (float(i) / j)\n",
    "print(total)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "916dbc7f-7a12-417e-bd0b-d6361193c0e5",
   "metadata": {},
   "source": [
    "### Always the first good option to try: Using NumPy\n",
    "The first thing you should get used to is using NumPy!\n",
    "It is in many cases directly the best we can get, at least without high additional effort."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "524d7644-4558-4534-9544-9d8e604b3f7e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "489223499.99918354\n",
      "CPU times: user 203 ms, sys: 0 ns, total: 203 ms\n",
      "Wall time: 201 ms\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "import numpy as np\n",
    "i = np.arange(9999)\n",
    "j = np.arange(1,9999)\n",
    "print(np.divide.outer(i,j).sum())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1588b141-077d-477e-852e-7daab5db92df",
   "metadata": {},
   "source": [
    "**This is enormeous improvement! As we will see, this will be hard to beat!**\n",
    "\n",
    "But we will try."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fdfe76a6-ee6a-430e-83fa-936a622042f0",
   "metadata": {},
   "source": [
    "### Let's Optimize!\n",
    "(Examples based on: https://stackoverflow.com/questions/8097408/why-python-is-so-slow-for-a-simple-for-loop)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c4b23d7d-7cd3-40af-9dfb-88b32b28283e",
   "metadata": {},
   "source": [
    "#### Let's wrap everything in a function "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "0c7761b3-6b8b-450d-97d1-8397cf48ec11",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 1: Let's make it a function!\n",
    "def f1(num):\n",
    "    total = 0.0\n",
    "    for i in range(num): \n",
    "        for j in range(1, num):\n",
    "            total += (float(i) / j)\n",
    "    return total"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "876f50bc-a5b1-4834-a288-44cdca1ae71e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "489223499.9991652\n",
      "CPU times: user 6.63 s, sys: 1.77 ms, total: 6.63 s\n",
      "Wall time: 6.64 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "print(f1(9999))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1ed855ac-2127-4a37-b0a7-78a2441ff7c4",
   "metadata": {},
   "source": [
    "**Question**: Any idea, why this is faster than the version before (without a function)?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f4a8b095-c6d6-43ab-83bb-b3b702d8b0c7",
   "metadata": {},
   "source": [
    "Your answer:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "e508def8-1977-4675-a42c-ac7d337a4125",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "When you define a function, Python compiles its bytecode once and it is reused each time you call it.\n",
      "For the global code, the entire loop is recompiled, which can cause an overhead.\n",
      "On top, inside the function, the variables are local, which is faster to access than global variables.\n",
      "Because in the global scope, variables are internally stored in a dictionary, the globals(), and accessing them is essentially a hash lookup. This is in general fast, but in tight loops, this is done thousands of times and adds up. This then can make loops in the global scope slightly slower.\n",
      "\n",
      "In a function, the variables are as well saved in a dict, the locals(), but accessing works differently. For each function call, a frame object pointer is created, which represents one execution fram and holds the functions local variables, arguments, and execution state. Inside this frame object, the variables are stored in optimized C arrays (so-called fast locals array) and can be accessed through a simple array access by index, which is way faster than a dict look up (as well O(1) complexity, but withput the overheads). On top, Python provides optimized bytecodes for these operations, the LOAD_FAST and STORE_FAST, which are used to access the array directly.\n",
      "This shows, using functions is a good practise! Not only, because it is organizing and structuring your code, it also can make it more performant!\n",
      "\n",
      "Further reading: https://peps.python.org/pep-0558/\n"
     ]
    }
   ],
   "source": [
    "from solutions import solution_speed4\n",
    "print(solution_speed4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "93e99cfd-b014-46db-a7a1-e10d962ab624",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Showcase: Dict lookup instead of fast array access -> THIS IS SLOWER\n",
    "def f1_b(num):\n",
    "    local_vars = locals()\n",
    "    local_vars['total'] = 0.0\n",
    "    for i in range(num):\n",
    "        for j in range(1, num):\n",
    "            local_vars['total'] += (float(i) / j)  # Dict lookup instead of LOAD_FAST/STORE_FAST\n",
    "    return local_vars['total']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "1bfd3d60-b64f-45ec-bd6f-0b7a2898a7d5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "489223499.9991652\n",
      "CPU times: user 10.1 s, sys: 3.84 ms, total: 10.1 s\n",
      "Wall time: 10.1 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "print(f1_b(9999))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ebd8623b-4534-486d-9233-4729cd54701d",
   "metadata": {},
   "source": [
    "#### Removing the Manual Cast"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "40ecadac-4965-4ca5-9118-523196bb04b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "def f2(num):\n",
    "    total = 0.0\n",
    "    for i in range(num): \n",
    "        for j in range(1, num):\n",
    "            total += (i / j)\n",
    "    return total"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "53b4ec2d-1cd0-405f-825c-1476383c0779",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "489223499.9991652\n",
      "CPU times: user 3.74 s, sys: 2.44 ms, total: 3.75 s\n",
      "Wall time: 3.75 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "print(f2(9999))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "4dae145e-38dc-4686-9b85-9306ec94e452",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Removing the cast allows Python to do internal optimization, which is often based on C implementations and therefore faster. This shows that if you are not entirely aware of how things are handled, it can be better to let it just do its job. But: we can do better!\n"
     ]
    }
   ],
   "source": [
    "from solutions import solution_speed5\n",
    "print(solution_speed5)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ddadf969-2939-40dd-985a-3dfba0d1152b",
   "metadata": {},
   "source": [
    "#### Using NumPy\n",
    "Typically the default way!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "f2d47b72-b84c-4c13-b157-068e5ce4d327",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "def f3(num):\n",
    "    i = np.arange(num, dtype=np.float64)\n",
    "    j = np.arange(1, num, dtype=np.float64)\n",
    "    return np.divide.outer(i, j).sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "83f27d27-12af-45f2-950e-a521b509ef67",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "489223499.99918354\n",
      "CPU times: user 74.8 ms, sys: 59.3 ms, total: 134 ms\n",
      "Wall time: 133 ms\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "print(f3(9999))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6f3e3763-f72b-43d7-9b56-0d8363b0f18c",
   "metadata": {},
   "source": [
    "Wow, already a very nice speedup without any big effort! And have a look, it is again faster than the initial NumPy version without a function."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bdb65553-1fa0-45b1-959c-f653bfaff189",
   "metadata": {},
   "source": [
    "#### Precision\n",
    "If not necessary, reducting the precision can help to optimize performance. But this highly depends on the problem!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "7e803624-12bf-4f14-986d-e78bf61b3c9e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Reducing precision, if not needed\n",
    "# See: https://numpy.org/doc/stable/user/basics.types.html\n",
    "import numpy as np\n",
    "def f4(num):\n",
    "    i = np.arange(num, dtype=np.float32)\n",
    "    j = np.arange(1, num, dtype=np.float32)\n",
    "    return np.divide.outer(i, j).sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "fd18993e-aa1e-4a7a-ab8f-fee5f3fbaef1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "489223300.0\n",
      "CPU times: user 41 ms, sys: 35.2 ms, total: 76.2 ms\n",
      "Wall time: 74.1 ms\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "print(f4(9999))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "65afd925-5a3e-4227-a58c-8733ae45a821",
   "metadata": {},
   "source": [
    "#### Using specialized (NumPy) Functions\n",
    "For some purposes, more optimized functions are available, such as np.true_divide in this case"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "8def1f20-bf27-4811-903e-e281f17ede3f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "def f5(num):\n",
    "    x=np.ones(num-1)\n",
    "    y=np.arange(1,num)\n",
    "    return np.sum(np.true_divide(x,y))*np.sum(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "b45c510b-b7aa-4029-9fe2-ac7fbbf4d894",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "489223499.99918455\n",
      "CPU times: user 2 ms, sys: 30 µs, total: 2.03 ms\n",
      "Wall time: 1.35 ms\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "print(f5(9999))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f5d7b519-9cf1-44f5-9ccc-3826374879f0",
   "metadata": {},
   "source": [
    "That is again a factor ~50! "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e6dd3557-0800-413d-9c8b-2739a47058dc",
   "metadata": {},
   "source": [
    "#### Be Smart!\n",
    "This is the most shittiest tip, but sometimes, it really helps, if you are just smart!\n",
    "For some problems, special algorithms or mathematical formulas exist.\n",
    "In this case, there is an explicit mathematical formulation of the problem!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "a231f701-1668-44fe-9a9b-c25c0062e86f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Being smart is typically the hardest optimization strategy (at least for me...)!\n",
    "import numpy as np\n",
    "def f6(num):\n",
    "    return np.sum(np.reciprocal(np.arange(1, num).astype(np.float64))) * num*(num-1)/2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "73c7f91b-ba25-4230-8599-4be459a6b858",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "489223499.9991845\n",
      "CPU times: user 1.19 ms, sys: 3 µs, total: 1.2 ms\n",
      "Wall time: 894 µs\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "print(f6(9999))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fcd8c7ac-ae89-400a-84b0-949c95107266",
   "metadata": {},
   "source": [
    "**NOTE: Since it is very fast, the restult can fluctuate. Run it multiple times!**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2383cac3-e303-4ea5-aa54-d7ac4e619599",
   "metadata": {},
   "source": [
    "**This is a very nice speedup!**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ff6f2956-a750-42c5-9ce2-c20abe1b58f4",
   "metadata": {},
   "source": [
    "### Wrap-Up"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "30935743-e13b-425c-9e84-1309a772eb76",
   "metadata": {},
   "source": [
    "The default option for optimizing numerical operations is NumPy and vectorization!\n",
    "Python loops execute one operation at a time in user space, with no SIMD (vectorized) optimization.\n",
    "\n",
    "NumPy instead delegate the entire loop to compiled C code, which runs at native speed and can use vector instructions (AVX, SSE).\n",
    "If you are interested, you can have a look at the optimizations for fast loops: \n",
    "\n",
    "https://github.com/numpy/numpy/blob/main/numpy/_core/src/umath/fast_loop_macros.h\n",
    "\n",
    "This let's us profit from fast C implementations while coding on a higher, more simplified abstraction level.\n",
    "\n",
    "\n",
    "Furthermore, we have seen: Other optimizations can be possible and useful, but the more specific it gets, the more problem dependend the approach is and no general recommendations can be given anymore."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dccb58d7-0d05-4a39-b04b-f128ec3de72e",
   "metadata": {},
   "source": [
    "**Question**: What else do you recognize?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c2e6020b-f0ce-4ce2-8fc3-5060ee98f0f1",
   "metadata": {},
   "source": [
    "Your answer:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "6a555230-ea41-4e2c-bde2-f5bf2ad7a11e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The results differ in some late digits! This is due to different precisions. This, you have always to take into account for your computations. E.g. if you need high precision, you MUST use float64, there is no way round and no way to optimize this.\n"
     ]
    }
   ],
   "source": [
    "from solutions import solution_speed3\n",
    "print(solution_speed3)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ef661e70-564e-47bc-ab00-b4ed2439ebfb",
   "metadata": {},
   "source": [
    "### Other Optimizations\n",
    "- Often it is possible to reduce the number of operations. Mainly with columnar data (\"vector additions\"). Numpy can handle that easily!\n",
    "- Using dicts, see below\n",
    "- Use native C code\n",
    "- Of course, there are many many more..."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "05b395d7-3307-46cc-8893-e5d4fe28ccc6",
   "metadata": {},
   "source": [
    "#### Using Dicts\n",
    "Of course, this is a very generic example, but ir proves the point that dicts can be very nice!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "38146550-b180-4f06-8481-f0ad222f36da",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dict lookup: 0.005 s\n",
      "list lookup: 93.794 s\n"
     ]
    }
   ],
   "source": [
    "import time\n",
    "import random\n",
    "import string\n",
    "\n",
    "# Generate random words\n",
    "N = 100000\n",
    "words = [''.join(random.choices(string.ascii_lowercase, k=5)) for _ in range(N)]\n",
    "\n",
    "# Select random sample to query\n",
    "queries = random.choices(words, k=50_000)\n",
    "\n",
    "# 1. Using dict\n",
    "d = {w: random.randint(0, 100) for w in words}\n",
    "start = time.perf_counter()\n",
    "_ = [d[q] for q in queries]  # O(1) lookup\n",
    "end = time.perf_counter()\n",
    "print(f\"dict lookup: {end - start:.3f} s\")\n",
    "\n",
    "# 2. Using list of tuples\n",
    "pairs = list(d.items())\n",
    "start = time.perf_counter()\n",
    "_ = [v for q in queries for k, v in pairs if k == q]  # O(n) per lookup\n",
    "end = time.perf_counter()\n",
    "print(f\"list lookup: {end - start:.3f} s\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "69cb81a5-9c1b-41ce-a112-a3289217b1b6",
   "metadata": {},
   "source": [
    "### Native C Code\n",
    "(Example taken from Sebastien Ponce/CERN: https://gitlab.cern.ch/sponce/tcsccourse)\n",
    "\n",
    "As already mentioned, Python can be used as a wrapper for large C(++) frameworks. This is a very common approach in the LHC environment and good practice.\n",
    "\n",
    "On top shown above, you can use precompiled C code within Python.\n",
    "This can come in very handy and is often used, when performance/runtime is a strict requirement.\n",
    "\n",
    "The given example calculates and plots https://en.wikipedia.org/wiki/Mandelbrot_set:\n",
    "```\n",
    "The Mandelbrot set is a two-dimensional set that is defined in the complex plane as the complex numbers c {\\displaystyle c} for which the function f c ( z ) = z 2 + c {\\displaystyle f_{c}(z)=z^{2}+c} does not diverge to infinity when iterated starting at z = 0 {\\displaystyle z=0}, i.e., for which the sequence f c ( 0 ) {\\displaystyle f_{c}(0)}, f c ( f c ( 0 ) ) {\\displaystyle f_{c}(f_{c}(0))}, etc., remains bounded in absolute value.\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c4114f8b-f869-4459-9026-a9a665dc4858",
   "metadata": {},
   "outputs": [],
   "source": [
    "!python3 speed_comparison/mandel/mandel_py.py --out mandel_py.png --bench --backend numpy"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e4783df2-1f44-4406-ad9d-0bf13591e3a2",
   "metadata": {},
   "source": [
    "If you want, you can try out the other backends as well."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a11619a6-e4e7-4759-9685-9bcb8dca805b",
   "metadata": {},
   "outputs": [],
   "source": [
    "!python3 speed_comparison/mandel/mandel_py.py -h"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d8172d6b-0bce-4108-a3ba-cfae83a62215",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get the C code\n",
    "!git clone https://gitlab.cern.ch/sponce/tcsccourse.git"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ce26335d-9a92-49c2-9d76-84863658cb8c",
   "metadata": {},
   "outputs": [],
   "source": [
    "!cd tcsccourse/exercises/exercise5 && make libmandel.so"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ffb92cb6-14ce-46cb-ad91-08e0ecb97e5a",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "!cd tcsccourse/exercises/exercise5 && export LD_LIBRARY_PATH=${LD_LIBRARY_PATH}:. && python3 mandel.py"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "704352a6-27ab-4818-8a8f-a61bfe7ea1ee",
   "metadata": {},
   "source": [
    "**Take-away:** Even with NumPy, Python is in general slower than low-level languages like C(++) or Rust, but if used correctly, we can get in range while maintaining most of Python's ease of use!"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6e489327-6de4-4f8b-aff8-d3e3e8dbf78f",
   "metadata": {},
   "source": [
    "## Bonus: Implicit vs Explicit -- Part II \n",
    "Remember the first example?\n",
    "When writing Python code, implicit concepts like chanining and list comprehensions can be helpful and reduce repetitions and bloated code.\n",
    "However, readibility suffers a lot, why it is **not** recommended for beginners."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f683a96f-54de-4fb4-a236-b84501a97752",
   "metadata": {},
   "source": [
    "**Question**: What do you thing is faster: implicit or explicit?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6e8e4d98-c946-4c05-922d-28fda696f6c5",
   "metadata": {},
   "source": [
    "Your answer:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8cadffb9-73fb-438c-bf67-0d889be03b10",
   "metadata": {},
   "outputs": [],
   "source": [
    "from solutions import solution_speed0\n",
    "print(solution_speed0)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8a72b054-d55f-4a55-b6c5-87a5be6be999",
   "metadata": {},
   "source": [
    "Try it out:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "71130877-9c7a-4fb1-b60c-fb13a52ca0bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "from functools import wraps\n",
    "\n",
    "def timing_decorator(func):\n",
    "    @wraps(func)  # This decorator preserves the original function's metadata\n",
    "    def wrapper(*args, **kwargs):\n",
    "        start = time.time()\n",
    "        result = func(*args, **kwargs)\n",
    "        end = time.time()\n",
    "        print(f\"{func.__name__} took {(end - start):.4f} seconds\")\n",
    "        return result\n",
    "    return wrapper\n",
    "\n",
    "def process(value):\n",
    "    print(f\"Processing {value}\")\n",
    "    return value.upper()\n",
    "\n",
    "ready = True\n",
    "data = \"apple\"\n",
    "default = \"banana\"\n",
    "N = 1000\n",
    "\n",
    "implicit_times = []\n",
    "explicit_times = []\n",
    "\n",
    "@timing_decorator\n",
    "def implicit():    \n",
    "    # --- Implicit and complex ---\n",
    "    start = time.perf_counter()\n",
    "    result = process(data or default) if ready else None\n",
    "    print(\"Implicit: \", result)\n",
    "\n",
    "@timing_decorator\n",
    "def explicit():\n",
    "    if ready:\n",
    "        if data:\n",
    "            result = process(data)\n",
    "        else:\n",
    "            result = process(default)\n",
    "    else:\n",
    "        result = None\n",
    "    print(\"Explicit: \", result)\n",
    "implicit()\n",
    "explicit()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "60f9bc2d-447c-4074-bd0c-12120f31e11c",
   "metadata": {},
   "source": [
    "**Question:** Why is the following implementation faster?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "82d23c85",
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "import statistics\n",
    "\n",
    "def process(value):\n",
    "    return value.upper()\n",
    "\n",
    "ready = True\n",
    "data = \"apple\"\n",
    "default = \"banana\"\n",
    "N = 1000\n",
    "\n",
    "implicit_times = []\n",
    "explicit_times = []\n",
    "\n",
    "for _ in range(N):\n",
    "    # --- Implicit and complex ---\n",
    "    start = time.perf_counter()\n",
    "    result = process(data or default) if ready else None\n",
    "    implicit_times.append(time.perf_counter() - start)\n",
    "\n",
    "    # --- Explicit and simple ---\n",
    "    start = time.perf_counter()\n",
    "    if ready:\n",
    "        if data:\n",
    "            result = process(data)\n",
    "        else:\n",
    "            result = process(default)\n",
    "    else:\n",
    "        result = None\n",
    "    explicit_times.append(time.perf_counter() - start)\n",
    "\n",
    "print(f\"Implicit avg: {statistics.mean(implicit_times):.8f}s ± {statistics.stdev(implicit_times):.8f}\")\n",
    "print(f\"Explicit avg: {statistics.mean(explicit_times):.8f}s ± {statistics.stdev(explicit_times):.8f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "32fddc46-ef2d-4b17-a29b-2fe45d07a371",
   "metadata": {},
   "source": [
    "Your answer:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "215cf5bb-6164-4ded-afe0-af8db2bf806b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from solutions import solution_speed1\n",
    "print(solution_speed1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7e199357-8dd4-414b-8eb9-63edbf35364e",
   "metadata": {},
   "source": [
    "------------------------"
   ]
  }
 ],
 "metadata": {
  "@webio": {
   "lastCommId": null,
   "lastKernelId": null
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
